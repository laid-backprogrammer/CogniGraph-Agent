# tools/knowledge_tools.py (ç»­)
"""
çŸ¥è¯†ç‚¹ç®¡ç†å·¥å…·
"""

from typing import Optional, List
from pydantic import BaseModel, Field

from .base import tool_registry, register_tool
from storage.base import KnowledgeNode


class AddKnowledgeNodeInput(BaseModel):
    """æ·»åŠ çŸ¥è¯†ç‚¹è¾“å…¥"""
    node_id: str = Field(description="çŸ¥è¯†ç‚¹åç§°/ID")
    description: str = Field(default="", description="çŸ¥è¯†ç‚¹æè¿°")
    difficulty: int = Field(default=1, ge=1, le=5, description="éš¾åº¦ç­‰çº§ 1-5")
    aliases: str = Field(default="", description="åˆ«åï¼Œé€—å·åˆ†éš”")


@register_tool(
    name="add_knowledge_node",
    description="æ·»åŠ æ–°çŸ¥è¯†ç‚¹åˆ°å›¾è°±ã€‚difficulty: 1=å…¥é—¨ 5=å›°éš¾ã€‚aliases: é€—å·åˆ†éš”çš„åˆ«å",
    args_schema=AddKnowledgeNodeInput
)
def add_knowledge_node(
        node_id: str,
        description: str = "",
        difficulty: int = 1,
        aliases: str = ""
) -> str:
    """æ·»åŠ çŸ¥è¯†ç‚¹èŠ‚ç‚¹"""
    try:
        graph_store = tool_registry.graph_store
        vector_store = tool_registry.vector_store

        # å¤„ç†åˆ«å
        alias_list = [a.strip() for a in aliases.split(",") if a.strip()] if aliases else []

        # å¤„ç† "A/B" æ ¼å¼
        if "/" in node_id:
            parts = node_id.split("/")
            real_id = parts[0].strip()
            for p in parts[1:]:
                if p.strip():
                    alias_list.append(p.strip())
            node_id = real_id

        # åˆ›å»ºèŠ‚ç‚¹
        node = KnowledgeNode(
            id=node_id,
            description=description,
            difficulty=difficulty,
            proficiency=0.0,
            aliases=list(set(alias_list))
        )

        # å­˜å‚¨åˆ°å›¾æ•°æ®åº“
        actual_id = graph_store.add_node(node)

        # åŒæ­¥åˆ°å‘é‡åº“
        search_text = f"{node_id} {description} {' '.join(alias_list)}".strip()
        vector_store.add(
            id=node_id,
            text=search_text,
            metadata={
                "name": node_id,
                "description": description,
                "aliases": ",".join(alias_list)
            }
        )

        return f"âœ… æˆåŠŸæ·»åŠ çŸ¥è¯†ç‚¹: {actual_id} (éš¾åº¦={difficulty})"
    except Exception as e:
        return f"âŒ æ·»åŠ å¤±è´¥: {str(e)}"


class QueryNodeInput(BaseModel):
    """æŸ¥è¯¢çŸ¥è¯†ç‚¹è¾“å…¥"""
    keyword: str = Field(description="è¦æŸ¥è¯¢çš„çŸ¥è¯†ç‚¹å…³é”®è¯")


@register_tool(
    name="query_node",
    description="æŸ¥è¯¢çŸ¥è¯†ç‚¹è¯¦æƒ…ï¼Œæ”¯æŒç²¾ç¡®åŒ¹é…å’Œè¯­ä¹‰æœç´¢",
    args_schema=QueryNodeInput
)
def query_node(keyword: str) -> str:
    """æŸ¥è¯¢çŸ¥è¯†ç‚¹"""
    try:
        graph_store = tool_registry.graph_store
        vector_store = tool_registry.vector_store

        keyword = keyword.strip()
        if "/" in keyword:
            keyword = keyword.split("/")[0].strip()

        # 1. ç²¾ç¡®åŒ¹é…
        node = graph_store.get_node(keyword)

        # 2. åˆ«ååŒ¹é…
        if not node:
            found_id = graph_store.find_by_alias(keyword)
            if found_id:
                node = graph_store.get_node(found_id)
                keyword = found_id

        # 3. è¯­ä¹‰æœç´¢
        if not node:
            results = vector_store.search(keyword, top_k=3)
            if results and results[0]['similarity'] >= 0.6:
                keyword = results[0]['id']
                node = graph_store.get_node(keyword)

        if not node:
            # ç»™å‡ºç›¸ä¼¼å»ºè®®
            similar = vector_store.search(keyword, top_k=3)
            if similar:
                suggestions = ", ".join([
                    f"{s['id']}({s['similarity']:.0%})" for s in similar
                ])
                return f"â“ æœªæ‰¾åˆ°: {keyword}\nğŸ’¡ ç›¸ä¼¼èŠ‚ç‚¹: {suggestions}"
            return f"â“ æœªæ‰¾åˆ°çŸ¥è¯†ç‚¹: {keyword}"

        # æ ¼å¼åŒ–è¾“å‡º
        prof = node.proficiency
        status = "ğŸ”´æœªå­¦ä¹ " if prof < 0.3 else "ğŸŸ¡å­¦ä¹ ä¸­" if prof < 0.7 else "ğŸŸ¢å·²æŒæ¡"
        prereqs = graph_store.get_prerequisites(keyword)
        prereq_str = f", å‰ç½®: {', '.join(prereqs)}" if prereqs else ""

        return (
            f"ğŸ“š {keyword}: {status}({prof:.0%}), éš¾åº¦={node.difficulty}{prereq_str}\n"
            f"   æè¿°: {node.description or 'æ— '}"
        )
    except Exception as e:
        return f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}"


class SearchSimilarInput(BaseModel):
    """æœç´¢ç›¸ä¼¼çŸ¥è¯†ç‚¹è¾“å…¥"""
    keyword: str = Field(description="æœç´¢å…³é”®è¯")
    top_k: int = Field(default=5, ge=1, le=20, description="è¿”å›ç»“æœæ•°é‡")


@register_tool(
    name="search_similar_nodes",
    description="å‘é‡è¯­ä¹‰æœç´¢ç›¸ä¼¼çŸ¥è¯†ç‚¹",
    args_schema=SearchSimilarInput
)
def search_similar_nodes(keyword: str, top_k: int = 5) -> str:
    """æœç´¢ç›¸ä¼¼çŸ¥è¯†ç‚¹"""
    try:
        graph_store = tool_registry.graph_store
        vector_store = tool_registry.vector_store

        results = vector_store.search(keyword, top_k)
        if not results:
            return f"â“ æ²¡æœ‰æ‰¾åˆ°ä¸ '{keyword}' ç›¸ä¼¼çš„çŸ¥è¯†ç‚¹"

        lines = [f"ğŸ” ä¸ '{keyword}' ç›¸ä¼¼çš„çŸ¥è¯†ç‚¹:"]
        for r in results:
            node = graph_store.get_node(r['id'])
            if node:
                prof = node.proficiency
                status = "ğŸŸ¢" if prof >= 0.7 else "ğŸŸ¡" if prof >= 0.3 else "ğŸ”´"
                lines.append(
                    f"  {status} {r['id']} (ç›¸ä¼¼åº¦: {r['similarity']:.0%}, ç†Ÿç»ƒåº¦: {prof:.0%})"
                )
        return "\n".join(lines)
    except Exception as e:
        return f"âŒ æœç´¢å¤±è´¥: {str(e)}"


class DeleteNodeInput(BaseModel):
    """åˆ é™¤çŸ¥è¯†ç‚¹è¾“å…¥"""
    node_id: str = Field(description="è¦åˆ é™¤çš„çŸ¥è¯†ç‚¹ID")


@register_tool(
    name="delete_knowledge_node",
    description="åˆ é™¤çŸ¥è¯†ç‚¹åŠå…¶ç›¸å…³ä¾èµ–",
    args_schema=DeleteNodeInput
)
def delete_knowledge_node(node_id: str) -> str:
    """åˆ é™¤çŸ¥è¯†ç‚¹"""
    try:
        graph_store = tool_registry.graph_store
        vector_store = tool_registry.vector_store

        # æŸ¥æ‰¾èŠ‚ç‚¹
        actual_id = graph_store.find_by_alias(node_id) or node_id
        node = graph_store.get_node(actual_id)

        if not node:
            return f"â“ æœªæ‰¾åˆ°: {node_id}"

        prereqs = graph_store.get_prerequisites(actual_id)
        dependents = graph_store.get_dependents(actual_id)

        # åˆ é™¤
        graph_store.delete_node(actual_id)
        vector_store.delete(actual_id)

        info = [f"âœ… å·²åˆ é™¤çŸ¥è¯†ç‚¹: {actual_id}"]
        if prereqs:
            info.append(f"   ç§»é™¤äº† {len(prereqs)} ä¸ªå‰ç½®ä¾èµ–")
        if dependents:
            info.append(f"   ç§»é™¤äº† {len(dependents)} ä¸ªåç»­ä¾èµ–")

        return "\n".join(info)
    except Exception as e:
        return f"âŒ åˆ é™¤å¤±è´¥: {str(e)}"


class ListNodesInput(BaseModel):
    """åˆ—å‡ºçŸ¥è¯†ç‚¹è¾“å…¥"""
    dummy: str = Field(default="", description="å ä½å‚æ•°ï¼Œå¯å¿½ç•¥")


@register_tool(
    name="list_all_nodes",
    description="åˆ—å‡ºæ‰€æœ‰çŸ¥è¯†ç‚¹åŠå…¶å­¦ä¹ çŠ¶æ€",
    args_schema=ListNodesInput
)
def list_all_nodes(dummy: str = "") -> str:
    """åˆ—å‡ºæ‰€æœ‰çŸ¥è¯†ç‚¹"""
    try:
        graph_store = tool_registry.graph_store
        nodes = graph_store.get_all_nodes()

        if not nodes:
            return "ğŸ“­ çŸ¥è¯†å›¾è°±ä¸ºç©ºï¼Œè¯·å…ˆæ·»åŠ çŸ¥è¯†ç‚¹"

        lines = ["ğŸ“š å½“å‰æ‰€æœ‰çŸ¥è¯†ç‚¹:", "-" * 40]

        # æŒ‰ç†Ÿç»ƒåº¦åˆ†ç»„
        mastered, learning, unlearned = [], [], []

        for node in nodes:
            prof = node.proficiency
            diff = node.difficulty
            desc = node.description[:20] if node.description else ""

            info = f"{node.id} ({prof:.0%}) {'â­' * diff}"
            if desc:
                info += f" - {desc}"

            if prof >= 0.7:
                mastered.append(info)
            elif prof >= 0.3:
                learning.append(info)
            else:
                unlearned.append(info)

        if mastered:
            lines.append(f"\nğŸŸ¢ å·²æŒæ¡ ({len(mastered)}):")
            for item in mastered:
                lines.append(f"  âœ“ {item}")

        if learning:
            lines.append(f"\nğŸŸ¡ å­¦ä¹ ä¸­ ({len(learning)}):")
            for item in learning:
                lines.append(f"  â— {item}")

        if unlearned:
            lines.append(f"\nğŸ”´ æœªå­¦ä¹  ({len(unlearned)}):")
            for item in unlearned:
                lines.append(f"  â—‹ {item}")

        stats = graph_store.get_statistics()
        lines.append(
            f"\nğŸ“Š ç»Ÿè®¡: {stats['node_count']}ä¸ªçŸ¥è¯†ç‚¹, "
            f"{stats['edge_count']}æ¡ä¾èµ–, {stats['problem_count']}é“é¢˜ç›®"
        )

        return "\n".join(lines)
    except Exception as e:
        return f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}"

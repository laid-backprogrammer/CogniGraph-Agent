# storage/vector_store.py
"""
å‘é‡å­˜å‚¨å®ç° - ChromaDB
"""

import json
from typing import Dict, List, Any, Optional
import chromadb
from openai import OpenAI

from config import get_settings
from .base import BaseVectorStorage


class EmbeddingService:
    """åµŒå…¥å‘é‡æœåŠ¡"""

    def __init__(self):
        settings = get_settings()
        self.client = OpenAI(
            api_key=settings.openai_api_key,
            base_url=settings.openai_base_url
        )
        self.model = settings.embedding_model
        self._cache: Dict[str, List[float]] = {}

    def embed(self, text: str) -> List[float]:
        """ç”ŸæˆåµŒå…¥å‘é‡"""
        if text in self._cache:
            return self._cache[text]

        try:
            response = self.client.embeddings.create(
                input=text,
                model=self.model
            )
            embedding = response.data[0].embedding
            self._cache[text] = embedding
            return embedding
        except Exception as e:
            print(f"âš ï¸ Embedding å¤±è´¥: {e}")
            return [0.0] * 1536

    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç”ŸæˆåµŒå…¥å‘é‡"""
        results = []
        uncached = []
        uncached_indices = []

        for i, text in enumerate(texts):
            if text in self._cache:
                results.append(self._cache[text])
            else:
                results.append(None)
                uncached.append(text)
                uncached_indices.append(i)

        if uncached:
            try:
                response = self.client.embeddings.create(
                    input=uncached,
                    model=self.model
                )
                for i, data in enumerate(response.data):
                    idx = uncached_indices[i]
                    results[idx] = data.embedding
                    self._cache[uncached[i]] = data.embedding
            except Exception as e:
                print(f"âš ï¸ Batch embedding å¤±è´¥: {e}")
                for idx in uncached_indices:
                    results[idx] = [0.0] * 1536

        return results


class ChromaVectorStore(BaseVectorStorage):
    """ChromaDB å‘é‡å­˜å‚¨"""

    def __init__(self, persist_dir: str = "./chroma_db"):
        self.client = chromadb.PersistentClient(path=persist_dir)
        self.collection = self.client.get_or_create_collection(
            name="knowledge_nodes",
            metadata={"hnsw:space": "cosine"}
        )
        self.embedding_service = EmbeddingService()

    def add(self, id: str, text: str, metadata: Dict[str, Any] = None) -> bool:
        """æ·»åŠ æˆ–æ›´æ–°å‘é‡"""
        metadata = metadata or {}
        embedding = self.embedding_service.embed(text)

        try:
            self.collection.upsert(
                ids=[id],
                embeddings=[embedding],
                metadatas=[metadata],
                documents=[text]
            )
            return True
        except Exception as e:
            print(f"âš ï¸ å‘é‡å­˜å‚¨å¤±è´¥: {e}")
            return False

    def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """æœç´¢ç›¸ä¼¼å‘é‡"""
        try:
            print(f"ğŸ” å‘é‡æœç´¢: {query}")
            query_embedding = self.embedding_service.embed(query)
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k,
                include=["metadatas", "distances", "documents"]
            )

            items = []
            if results['ids'] and results['ids'][0]:
                for i, id in enumerate(results['ids'][0]):
                    distance = results['distances'][0][i] if results['distances'] else 1.0
                    metadata = results['metadatas'][0][i] if results['metadatas'] else {}
                    document = results['documents'][0][i] if results['documents'] else ""

                    items.append({
                        "id": id,
                        "similarity": 1 - distance,
                        "metadata": metadata,
                        "document": document
                    })
            print(f"ğŸ” å‘é‡æœç´¢ç»“æœ: {json.dumps(items, ensure_ascii=False)}")
            return items
        except Exception as e:
            print(f"âš ï¸ å‘é‡æœç´¢å¤±è´¥: {e}")
            return []

    def delete(self, id: str) -> bool:
        """åˆ é™¤å‘é‡"""
        try:
            self.collection.delete(ids=[id])
            return True
        except Exception:
            return False

    def clear(self) -> bool:
        """æ¸…ç©ºæ‰€æœ‰å‘é‡"""
        try:
            self.collection.delete(where={})
            return True
        except Exception:
            return False
